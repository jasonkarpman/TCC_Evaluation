{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "* Database access requires us to add your IP to the AWS security list, contact Eric Dasmalchi or Jason Karpman for access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from arcgis2geojson import arcgis2geojson\n",
    "import requests\n",
    "import mysql\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up database conenction. \n",
    "#Must add IP to security list on AWS console first.\n",
    "config = {\n",
    "  'user': 'luskincenter',\n",
    "  'password': os.environ['TCC_SQL_PWD'],\n",
    "  'host': 'housing-site-db.cxxl1so9sozw.us-west-1.rds.amazonaws.com',\n",
    "  'database': 'housing_site_db',\n",
    "  'raise_on_warnings': True\n",
    "}\n",
    "try:\n",
    "    cnx = mysql.connector.connect(**config)\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
    "        print(\"Something is wrong with your user name or password\")\n",
    "    elif err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "        print(\"Database does not exist\")\n",
    "    else:\n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2020_data(city):\n",
    "    \n",
    "    def rentdf_to_gdf(rent_df):\n",
    "        rent_df = rent_df.replace('', np.nan).dropna(subset=['lat', 'lng'])\n",
    "        rent_gdf = gpd.GeoDataFrame(\n",
    "            rent_df, geometry=gpd.points_from_xy(\n",
    "            rent_df['lng'].astype('float64'), rent_df['lat'].astype('float64')))\n",
    "        return rent_gdf\n",
    "\n",
    "    #reformat 2020 data to generally match 2014 data\n",
    "    def match_2014_data(gdf_2020rent):\n",
    "        gdf_2020rent['date'] = gdf_2020rent['dt'].apply(lambda x: x[:11])\n",
    "        gdf_2020rent = gdf_2020rent.rename(columns={'price':'rent',\n",
    "                                                    'beds':'bedrooms',\n",
    "                                                   'lat':'latitude',\n",
    "                                                   'lng':'longitude'})\n",
    "        gdf_2020rent = gdf_2020rent.drop_duplicates(subset=['rent', 'sqft', 'date'])\n",
    "        gdf_2020rent = gdf_2020rent.dropna(subset=['rent', 'sqft'])\n",
    "        gdf_2020rent = gdf_2020rent.replace('', np.nan).dropna(subset=[\n",
    "                                'latitude', 'longitude', 'rent', 'sqft'])\n",
    "        gdf_2020rent['rent'] = gdf_2020rent.loc[:,'rent'].astype(int)\n",
    "        gdf_2020rent['sqft'] = gdf_2020rent.loc[:,'sqft'].astype(int)\n",
    "        return gdf_2020rent\n",
    "\n",
    "    assert city in ['la', 'ontario', 'fresno']\n",
    "    print(f'Getting craigslist data for {city}... ', end = '')\n",
    "    cols = 'pid, dt, price, beds, sqft, lat, lng, region, domain'\n",
    "    regions = {'la':['Watts1', 'Watts2'], 'ontario':['Ontario'], 'fresno':['Fresno']}\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for region in regions[city]:\n",
    "        query = f\"SELECT {cols} FROM housing_site_db.craigslist_table WHERE region = '{region}'\\\n",
    "    AND STR_TO_DATE(dt, '%Y-%m-%d %H:%i') BETWEEN '2020-05-01' AND '2020-08-01';\"\n",
    "        query_df = pd.read_sql(query, con=cnx)\n",
    "        df = df.append(query_df)\n",
    "    \n",
    "    #add variable for DiD analysis\n",
    "    df['time'] = 1\n",
    "    df = df.reset_index()\n",
    "    print('Done!')\n",
    "    \n",
    "    return match_2014_data(rentdf_to_gdf(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting craigslist data for fresno... Done!\n"
     ]
    }
   ],
   "source": [
    "fres_listings_20 = get_2020_data('fresno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting craigslist data for la... Done!\n"
     ]
    }
   ],
   "source": [
    "la_listings_20 = get_2020_data('la')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting craigslist data for ontario... Done!\n"
     ]
    }
   ],
   "source": [
    "ont_listings_20 = get_2020_data('ontario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include only apartments/rooms from 2020 data\n",
    "def filter_apt_only(listing_gdf):\n",
    "    assert 'domain' in listing_gdf.columns\n",
    "    #new column to extract type of listing from domain\n",
    "    listing_gdf['type_code'] = listing_gdf['domain'].apply(lambda x: x.split('/')[-1])\n",
    "    #filter to only apartment and room listings (exclude for-sale properties)\n",
    "    listing_gdf = listing_gdf.loc[listing_gdf['type_code'].isin(['apa', 'roo'])]\n",
    "    return listing_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fres_listings_20 = filter_apt_only(fres_listings_20)\n",
    "la_listings_20 = filter_apt_only(la_listings_20)\n",
    "ont_listings_20 = filter_apt_only(ont_listings_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fres_listings_20.to_file('craigslist_data/2020/fresno_listings.geojson', driver='GeoJSON')\n",
    "# la_listings_20.to_file('craigslist_data/2020/la_listings.geojson', driver='GeoJSON')\n",
    "# ont_listings_20.to_file('craigslist_data/2020/ontario_listings.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIPS codes for census tracts included in our control and tcc groups for each region\n",
    "la_tracts = {'control': ['06037239601', '06037219901', '06037232120', '06037221500',\n",
    "                          '06037237720', '06037238310', '06037238320', '06037237710',\n",
    "                          '06037241120', '06037231100', '06037231210', '06037231300',\n",
    "                           '06037231600', '06037231710', '06037240500', '06037237500',\n",
    "                           '06037232500', '06037232700', '06037240600', '06037237101',\n",
    "                           '06037237202', '06037237401', '06037239202', '06037239501',\n",
    "                           '06037239602', '06037239802', '06037239801', '06037228500',\n",
    "                            '06037231720', '06037237102', '06037241400', '06037240010',\n",
    "                      '06037241202', '06037240401', '06037541604', '06037535102',\n",
    "                      '06037540901', '06037600304'],\n",
    "              'tcc': ['06037241001', '06037240900', '06037242700', '06037242100',\n",
    "                     '06037242000', '06037240800', '06037242300', '06037242200',\n",
    "                     '06037243000', '06037242600', '06037243100']}\n",
    "\n",
    "fresno_tracts = {'control': ['06019001202', '06019001304', '06019001407', '06019002800',\n",
    "                          '06019003202', '06019003807', '06019004704', '06019004802',\n",
    "                          '06019005100', '06019005403'],\n",
    "              'tcc': ['06019000700', '06019001100', '06019001000', '06019000901',\n",
    "                     '06019000200', '06019000300', '06019000400', '06019000600',\n",
    "                     '06019000902', '06019000100']}\n",
    "\n",
    "ontario_tracts = {'control': ['06071000603', '06071003803', '06071000207', '06071002804',\n",
    "                          '06071002602', '06071002902', '06071003200', '06071003102',\n",
    "                          '06071003301', '06071003101', '06071003509', '06071004700',\n",
    "                           '06071004604', '06071006700', '06071007000', '06071000201',\n",
    "                           '06071003401', '06071000904', '06071001104', '06071001001',\n",
    "                           '06071001305', '06071003607', '06071006604', '06071002204',\n",
    "                           '06071006302', '06071000303', '06071002402', '06071002401',\n",
    "                            '06071002501', '06071003302'],\n",
    "              'tcc': ['06071001600', '06071001702', '06071001400', '06071001813',\n",
    "                     '06071001707', '06071001812', '06071001504', '06071001706',\n",
    "                     '06071001501', '06071001503']}\n",
    "\n",
    "#get geography for all control and tcc tracts in a region\n",
    "def ctrl_tcc_tract_gdfs(city):\n",
    "    \n",
    "    def get_tracts_geog(geoid_list):\n",
    "        def get_tract_geog(geoid):\n",
    "            api_url = 'https://tigerweb.geo.census.gov/arcgis/rest/services/TIGERweb/tigerWMS_ACS2016/MapServer/8/query?f=json&outsr=4326&where=GEOID={}'\n",
    "            data = requests.get(api_url.format(geoid)).json()\n",
    "            data = arcgis2geojson(data)\n",
    "            #print(data)\n",
    "            gdf = gpd.GeoDataFrame.from_features(data['features'])\n",
    "            gdf['geoid'] = geoid\n",
    "\n",
    "            return gdf.set_index('geoid')\n",
    "        \n",
    "        for geoid in geoid_list:\n",
    "            try:\n",
    "                gdf = gdf.append(get_tract_geog(geoid))\n",
    "            except NameError:\n",
    "                gdf = get_tract_geog(geoid)\n",
    "        return gdf\n",
    "    \n",
    "        \n",
    "    print(f'Getting tract shape data for {city}... ', end = '')\n",
    "    assert city in ['la', 'ontario', 'fresno']\n",
    "    if city == 'la':\n",
    "        ctrl_tracts = get_tracts_geog(la_tracts['control'])\n",
    "        tcc_tracts = get_tracts_geog(la_tracts['tcc'])\n",
    "    elif city == 'ontario':\n",
    "        ctrl_tracts = get_tracts_geog(ontario_tracts['control'])\n",
    "        tcc_tracts = get_tracts_geog(ontario_tracts['tcc'])\n",
    "    elif city == 'fresno':\n",
    "        ctrl_tracts = get_tracts_geog(fresno_tracts['control'])\n",
    "        tcc_tracts = get_tracts_geog(fresno_tracts['tcc'])\n",
    "        \n",
    "    #assign numeric treatment group variable for DiD analysis\n",
    "    ctrl_tracts['group'] = 0\n",
    "    tcc_tracts['group'] = 1\n",
    "    \n",
    "    print('Done!')\n",
    "    return ctrl_tracts.append(tcc_tracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tract shape data for fresno... Done!\n",
      "Getting tract shape data for la... Done!\n",
      "Getting tract shape data for ontario... Done!\n"
     ]
    }
   ],
   "source": [
    "fres_tracts = ctrl_tcc_tract_gdfs('fresno')\n",
    "la_tracts = ctrl_tcc_tract_gdfs('la')\n",
    "ont_tracts = ctrl_tcc_tract_gdfs('ontario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fres_tracts.to_file('craigslist_data/tracts/fresno_tracts.geojson', driver='GeoJSON')\n",
    "la_tracts.to_file('craigslist_data/tracts/la_tracts.geojson', driver='GeoJSON')\n",
    "ont_tracts.to_file('craigslist_data/tracts/ontario_tracts.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_to_tracts(listing_gdf, tracts_gdf):\n",
    "    sjoined_gdf = gpd.sjoin(listing_gdf, tracts_gdf, how='left', op='within')\n",
    "    sjoined_gdf = (\n",
    "                    #drop listings not in TCC nor control group\n",
    "                    sjoined_gdf.dropna(subset=['group'])\n",
    "                    #.rename(columns={'index_right': 'tract_id'})\n",
    "                    .drop(columns='BASENAME')\n",
    "                    )\n",
    "    return sjoined_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_to_tracts(fres_listings_20, fres_tracts).to_file(\n",
    "    'craigslist_data/2020/fresno_listings.geojson', driver='GeoJSON')\n",
    "join_to_tracts(la_listings_20, la_tracts).to_file(\n",
    "    'craigslist_data/2020/la_listings.geojson', driver='GeoJSON')\n",
    "join_to_tracts(ont_listings_20, ont_tracts).to_file(\n",
    "    'craigslist_data/2020/ontario_listings.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
